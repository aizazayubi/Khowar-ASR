{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c747bee4612438c9d2c9df13555c727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_930bb29c564844cbbedeb746d23a3e68",
              "IPY_MODEL_b6e7b5f9f0264997862f6cfb4280fe9e",
              "IPY_MODEL_fb5b27be5d2548ad993cd1021fa74d89"
            ],
            "layout": "IPY_MODEL_472bd6d1e3f9487f8b984c691ffa5d48"
          }
        },
        "930bb29c564844cbbedeb746d23a3e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e66b74d4f2445ccb1a440d5fddd2391",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff0cf9d478e45f98e3db1c332d12f44",
            "value": "Map: 100%"
          }
        },
        "b6e7b5f9f0264997862f6cfb4280fe9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20ca79f7bbb9492c93df3f83a54c4a6b",
            "max": 1599,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e31ee7e6eba149b4ada577e7eb8f8a8f",
            "value": 1599
          }
        },
        "fb5b27be5d2548ad993cd1021fa74d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c03674214c2e419ea96750fc39d51c28",
            "placeholder": "​",
            "style": "IPY_MODEL_f897286d49d34ec8ac5290596daa1c45",
            "value": " 1599/1599 [11:47&lt;00:00,  2.87 examples/s]"
          }
        },
        "472bd6d1e3f9487f8b984c691ffa5d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e66b74d4f2445ccb1a440d5fddd2391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff0cf9d478e45f98e3db1c332d12f44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20ca79f7bbb9492c93df3f83a54c4a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e31ee7e6eba149b4ada577e7eb8f8a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c03674214c2e419ea96750fc39d51c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f897286d49d34ec8ac5290596daa1c45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eea0d011d3c4cf593f9196112fced8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e73c7a4b4884e2db4eef5c134e3c8f6",
              "IPY_MODEL_62d6cc11b9f849c48c43210c14e8a1ef",
              "IPY_MODEL_f93352b055084348b3a3f9a5718a42ec"
            ],
            "layout": "IPY_MODEL_600fccc616834c8988928b3435efec3a"
          }
        },
        "5e73c7a4b4884e2db4eef5c134e3c8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1156c7883c0c49f7a88b0362bed1a21c",
            "placeholder": "​",
            "style": "IPY_MODEL_affff920a6a941cc851b3917e59a0eca",
            "value": "Map: 100%"
          }
        },
        "62d6cc11b9f849c48c43210c14e8a1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeee7ed5812d467289a751a3041b8d7a",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5af5e34ec72446c298354142da2238ba",
            "value": 199
          }
        },
        "f93352b055084348b3a3f9a5718a42ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e3a12fb674941728c6a51f262d06b9a",
            "placeholder": "​",
            "style": "IPY_MODEL_b87c3d986c264569b5420ae077ab280f",
            "value": " 199/199 [01:20&lt;00:00,  2.25 examples/s]"
          }
        },
        "600fccc616834c8988928b3435efec3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1156c7883c0c49f7a88b0362bed1a21c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "affff920a6a941cc851b3917e59a0eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeee7ed5812d467289a751a3041b8d7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5af5e34ec72446c298354142da2238ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e3a12fb674941728c6a51f262d06b9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87c3d986c264569b5420ae077ab280f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASR for Khowar using Whisper Model\n",
        "In this Notebook, we have used Whisper, an automatic speech recognition (ASR) system, to fine-tune a model for the Khowar language. Since Khowar is a low-resource language with limited training data, we used the pre-trained model of Urdu as a starting point. The main reason for choosing Urdu is that both Urdu and Khowar use the same writing script. This similarity in their written form makes it easier for the model to learn and recognize Khowar speech more accurately. By building on the Urdu model, we were able to improve the performance of Whisper for Khowar ASR tasks.\n",
        "\n",
        "**Whisper:** Whisper is an automatic speech recognition (ASR) system developed by OpenAI. It converts spoken language into written text using deep learning. Whisper is trained on a large, diverse dataset of multilingual and multitask audio, making it highly accurate and capable of understanding various languages, accents, and background noise conditions."
      ],
      "metadata": {
        "id": "7DeezA59Hzm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Import and install Necessary Libraries"
      ],
      "metadata": {
        "id": "JeeGBDvRJ4pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #installing necessary libraries\n",
        "# !pip install datasets>=2.6.1\n",
        "# !pip install git+https://github.com/huggingface/transformers\n",
        "# !pip install librosa\n",
        "# !pip install evaluate>=0.30\n",
        "# !pip install jiwer\n",
        "# !pip install gradio"
      ],
      "metadata": {
        "id": "UlDDRUK-wnEZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ppZ4I0f8NPn"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from datasets import Audio\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Load and Prepare Dataset"
      ],
      "metadata": {
        "id": "HDU7K0i5HnEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/thesis/data/train.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/MyDrive/thesis/data/test.csv\")\n",
        "\n",
        "# Add the directory path to the filenames\n",
        "train_df['path'] = \"/content/drive/MyDrive/thesis/data/labeled/\" + train_df['path']\n",
        "test_df['path'] = \"/content/drive/MyDrive/thesis/data/labeled/\" + test_df['path']"
      ],
      "metadata": {
        "id": "x0auGotr8hHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns = [\"path\", \"sentence\"]\n",
        "test_df.columns = [\"path\", \"sentence\"]"
      ],
      "metadata": {
        "id": "HMGlqL-zEbH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ],
      "metadata": {
        "id": "_Dk7lMEMEibY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.cast_column(\"path\", Audio(sampling_rate=16000))\n",
        "test_dataset = test_dataset.cast_column(\"path\", Audio(sampling_rate=16000))"
      ],
      "metadata": {
        "id": "bISHCXvTEnB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Import Feature Extractor and Whisper Tokenizer"
      ],
      "metadata": {
        "id": "6bbvQHsVKUw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## import feature extractor\n",
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "## Load WhisperTokenizer\n",
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-base\", language=\"Urdu\", task=\"transcribe\")"
      ],
      "metadata": {
        "id": "bf07wLbVEwAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Create Whisper Processor"
      ],
      "metadata": {
        "id": "worbPD3_KrOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Combine To Create A WhisperProcessor\n",
        "from transformers import WhisperProcessor\n",
        "\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\", language=\"Urdu\", task=\"transcribe\")"
      ],
      "metadata": {
        "id": "PYyDHE0uE_G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Preparing and Maping Dataset"
      ],
      "metadata": {
        "id": "l5rMoruaK-RG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(examples):\n",
        "    # compute log-Mel input features from input audio array\n",
        "    audio = examples[\"path\"]\n",
        "    examples[\"input_features\"] = feature_extractor(\n",
        "        audio[\"array\"], sampling_rate=16000).input_features[0]\n",
        "    del examples[\"path\"]\n",
        "    sentences = examples[\"sentence\"]\n",
        "\n",
        "    # encode target text to label ids\n",
        "    examples[\"labels\"] = tokenizer(sentences).input_ids\n",
        "    del examples[\"sentence\"]\n",
        "    return examples"
      ],
      "metadata": {
        "id": "VwpdUl9UFH9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(prepare_dataset, num_proc=1)\n",
        "test_dataset = test_dataset.map(prepare_dataset, num_proc=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "8c747bee4612438c9d2c9df13555c727",
            "930bb29c564844cbbedeb746d23a3e68",
            "b6e7b5f9f0264997862f6cfb4280fe9e",
            "fb5b27be5d2548ad993cd1021fa74d89",
            "472bd6d1e3f9487f8b984c691ffa5d48",
            "1e66b74d4f2445ccb1a440d5fddd2391",
            "6ff0cf9d478e45f98e3db1c332d12f44",
            "20ca79f7bbb9492c93df3f83a54c4a6b",
            "e31ee7e6eba149b4ada577e7eb8f8a8f",
            "c03674214c2e419ea96750fc39d51c28",
            "f897286d49d34ec8ac5290596daa1c45",
            "8eea0d011d3c4cf593f9196112fced8b",
            "5e73c7a4b4884e2db4eef5c134e3c8f6",
            "62d6cc11b9f849c48c43210c14e8a1ef",
            "f93352b055084348b3a3f9a5718a42ec",
            "600fccc616834c8988928b3435efec3a",
            "1156c7883c0c49f7a88b0362bed1a21c",
            "affff920a6a941cc851b3917e59a0eca",
            "eeee7ed5812d467289a751a3041b8d7a",
            "5af5e34ec72446c298354142da2238ba",
            "3e3a12fb674941728c6a51f262d06b9a",
            "b87c3d986c264569b5420ae077ab280f"
          ]
        },
        "id": "S1cC_RutFlTA",
        "outputId": "86db096f-0120-4ffa-e2c5-58f9f9281dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1599 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c747bee4612438c9d2c9df13555c727"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/199 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8eea0d011d3c4cf593f9196112fced8b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Collector Difinition"
      ],
      "metadata": {
        "id": "CxeZ_xOiLhF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
        "        # first treat the audio inputs by simply returning torch tensors\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "        # get the tokenized label sequences\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        # pad the labels to max length\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "        # if bos token is appended in previous tokenization step,\n",
        "        # cut bos token here as it's append later anyways\n",
        "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "## lets initiate the data collator\n",
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
      ],
      "metadata": {
        "id": "HXHaSzfNKMFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Evaluation Matrics Definition"
      ],
      "metadata": {
        "id": "Jc5aGSZPLuFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"wer\")"
      ],
      "metadata": {
        "id": "In-4nkg_KXSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "    return {\"wer\": wer}"
      ],
      "metadata": {
        "id": "-eVXlAAZKzEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a Pre-Trained Checkpoint\n",
        "from transformers import WhisperForConditionalGeneration\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "# Explicitly set gradient_checkpointing to False on the model config\n",
        "model.config.gradient_checkpointing = False"
      ],
      "metadata": {
        "id": "Tkc8zhATK5Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.forced_decoder_ids = None\n",
        "model.config.suppress_tokens = []"
      ],
      "metadata": {
        "id": "l-CHNhJ3LCD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Training"
      ],
      "metadata": {
        "id": "wN51amopL3_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Training Arguments\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./whisper-base-kho\",  # change to a repo name of your choice\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
        "    learning_rate=1e-5,\n",
        "    warmup_steps=500,\n",
        "    max_steps=15000,\n",
        "    gradient_checkpointing=False, # Changed to False\n",
        "    fp16=True,\n",
        "    eval_strategy=\"steps\",\n",
        "    per_device_eval_batch_size=1,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=225,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    # logging_steps=25,\n",
        "    report_to=[\"tensorboard\"],\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"wer\",\n",
        "    greater_is_better=False,\n",
        "    push_to_hub=False,\n",
        ")\n",
        "\n",
        "from transformers import Seq2SeqTrainer\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_ids = pred.predictions\n",
        "    label_ids = pred.label_ids\n",
        "\n",
        "    # replace -100 with the pad_token_id\n",
        "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
        "\n",
        "    # Ensure inputs to batch_decode are numpy arrays\n",
        "    pred_str = tokenizer.batch_decode(np.asarray(pred_ids), skip_special_tokens=True)\n",
        "    label_str = tokenizer.batch_decode(np.asarray(label_ids), skip_special_tokens=True)\n",
        "\n",
        "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
        "    return {\"wer\": wer}\n",
        "\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    # Use processing_class instead of tokenizer as recommended by the warning\n",
        "    processing_class=processor,\n",
        ")\n",
        "\n",
        "## start the model training\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "uzVMA8l5LDca",
        "outputId": "93ee0b1e-8183-4441-cf6b-7cc632411d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4305' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4305/15000 3:12:02 < 7:57:17, 0.37 it/s, Epoch 43.04/150]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Wer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.105300</td>\n",
              "      <td>0.773119</td>\n",
              "      <td>69.746083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.166900</td>\n",
              "      <td>0.890454</td>\n",
              "      <td>65.099946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.020800</td>\n",
              "      <td>1.154179</td>\n",
              "      <td>62.452728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.004500</td>\n",
              "      <td>1.191722</td>\n",
              "      <td>62.452728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>1.277595</td>\n",
              "      <td>61.858455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>1.237094</td>\n",
              "      <td>65.532145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>1.285191</td>\n",
              "      <td>62.020529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>1.351269</td>\n",
              "      <td>61.048082</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
            "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3685: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results and Discussion\n",
        "The Whisper model was fine-tuned on approximately 2 hours of labeled Khowar audio data using the pretrained base model for Urdu. This choice was intentional, as Khowar and Urdu share a similar script, making Urdu a suitable base for transfer learning.\n",
        "\n",
        "After training for **4,000 steps** (out of the planned 15,000), the model achieved a **Word Error Rate (WER) of 61.04%**, which is considered a promising result given the limited data and compute resources. Training was stopped early due to hardware constraints.\n",
        "\n",
        "The result highlights Whisper's robustness and the potential of low-resource language adaptation using related language models. While the WER is still high, it establishes a solid baseline for future improvements, such as:\n",
        "\n",
        "* Increasing dataset size and dialectal variety\n",
        "* Using more compute for full training\n",
        "* Experimenting with larger Whisper variants or multilingual pretraining\n",
        "\n",
        "Overall, this experiment demonstrates that fine-tuning Whisper on a small Khowar dataset using Urdu as a base model is a viable approach for building ASR systems in underrepresented languages.\n"
      ],
      "metadata": {
        "id": "Ba5P3IbYvi5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo with Best Checkpoint"
      ],
      "metadata": {
        "id": "qILYyqT6ML_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from transformers import WhisperForConditionalGeneration, WhisperProcessor\n",
        "\n",
        "# === Load Model and Processor ===\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"/content/drive/MyDrive/WHISPER_KHOWAR\")\n",
        "processor = WhisperProcessor.from_pretrained(\"/content/drive/MyDrive/WHISPER_KHOWAR\")\n",
        "\n",
        "# === Load and Preprocess Audio ===\n",
        "file_path = \"/content/voice.wav\"  # Your .wav file\n",
        "waveform, sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "# Resample if not 16kHz\n",
        "if sample_rate != 16000:\n",
        "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "    waveform = resampler(waveform)\n",
        "\n",
        "# Convert to 1D numpy array\n",
        "audio = waveform.squeeze().numpy()\n",
        "\n",
        "# === Prepare Input ===\n",
        "inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\")\n",
        "\n",
        "# === Run Inference ===\n",
        "with torch.no_grad():\n",
        "    predicted_ids = model.generate(inputs[\"input_features\"])\n",
        "\n",
        "# === Decode and Print Transcription ===\n",
        "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "print(\"Transcription:\", transcription)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWvQzQJNBaXT",
        "outputId": "72d63ec5-b9ea-4c93-cb89-c6b072007530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
            "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n",
            "`generation_config` default values have been modified to match model-specific defaults: {'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. If this is not desired, please set these values explicitly.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensLogitsProcessor'> to see related `.generate()` flags.\n",
            "A custom logits processor of type <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> has been passed to `.generate()`, but it was also created in `.generate()`, given its parameterization. The custom <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> will take precedence. Please check the docstring of <class 'transformers.generation.logits_process.SuppressTokensAtBeginLogitsProcessor'> to see related `.generate()` flags.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:  اننا اان مسہ زائیلہ ہیس ماروٹیین ہمیشہ زباک دست\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s3eOX--eDeGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}