# -*- coding: utf-8 -*-
"""Speech Corpus

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CuIQfvGJ8Kh7Q15heviGqv4O3PyXTDO9

# Speech Corpus

The purpose of this code is to reads a CSV file containing YouTube links, downloads the audio from each link using `yt-dlp`, and splits the downloaded audio into chunks of 3 to 8 seconds using `pydub`. For each link in the CSV, the script saves the audio in a directory and creates separate directories (`chunks_0`, `chunks_1`, etc.) for the audio chunks, organizing the chunks for each video individually. This way, the script handles multiple YouTube links efficiently, downloading and processing each one in sequence. After getting chunks of audios I will use that audio chunks for my Wav2Vec thesis as dataset
"""

pip install yt-dlp pydub

"""# **Import Libraries**"""

import yt_dlp
from pydub import AudioSegment
import os
import random
import pandas as pd

"""# Extract Audtion from Youtube
This code defines options for audio format and output, uses yt-dlp to download and extract the audio, and returns the path to the saved MP3 file.

"""

def download_audio_from_youtube(youtube_link, output_path="/content/drive/MyDrive/SpeechCorpus/"):
    ydl_opts = {
        'format': 'bestaudio/best',
        'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'),
        'postprocessors': [{
            'key': 'FFmpegExtractAudio',
            'preferredcodec': 'mp3',
            'preferredquality': '192',
        }],
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info_dict = ydl.extract_info(youtube_link, download=True)
        audio_file_path = ydl.prepare_filename(info_dict).rsplit('.', 1)[0] + '.mp3'
    return audio_file_path

"""# Split audios into chunks
This code will split audios into 3-8 sec chunks and save them in directories

"""

def split_audio_into_chunks(audio_file_path, min_chunk_length=3, max_chunk_length=8, output_path="/content/drive/MyDrive/SpeechCorpus/"):
    if not os.path.exists(output_path):
        os.makedirs(output_path)

    audio = AudioSegment.from_file(audio_file_path)
    audio_length_ms = len(audio)

    start = 0
    chunk_number = 1

    while start < audio_length_ms:
        chunk_length = random.randint(min_chunk_length, max_chunk_length) * 1000
        end = min(start + chunk_length, audio_length_ms)
        chunk = audio[start:end]
        chunk.export(f"{output_path}/chunk_{chunk_number}.mp3", format="mp3")
        chunk_number += 1
        start = end

def process_youtube_links_from_csv(csv_file):
    df = pd.read_csv(csv_file)
    for index, row in df.iterrows():
        youtube_link = row['links']
        print(f"Processing: {youtube_link}")
        try:
            audio_file_path = download_audio_from_youtube(youtube_link)
            split_audio_into_chunks(audio_file_path, output_path=f"chunks_{index}")
        except Exception as e:
            print(f"Failed to process {youtube_link}: {e}")

if __name__ == "__main__":
    csv_file = "/content/drive/MyDrive/SpeechCorpus/links.csv"
    process_youtube_links_from_csv(csv_file)

"""# Conclusion

In conclusion, the provided code efficiently handles the task of downloading audio from multiple YouTube links and splitting it into short segments. The main function reads a CSV file of YouTube links, uses `yt-dlp` to download the audio for each link, and then employs `pydub` to split the audio into random chunks of 3 to 8 seconds. The script organizes the audio files and chunks into directories for easy management. This approach automates the process, making it convenient to handle large datasets of YouTube links and convert them into manageable audio segments.
"""

